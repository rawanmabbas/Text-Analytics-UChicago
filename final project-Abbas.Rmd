---
title: "final project"
output:
  pdf_document: default
  html_document: default
date: '2022-05-23'
---

Text mining with Random Forest is vital because its model operates as a collection of several decision trees. Each decision tree contains several predictor variables. Then each of these decision trees produces an output class. The class with the majority of votes gets picked. For example, if we have 10 decision trees under a Random Forest model, we would choose the output class that is recorded by 6 out of these 10 trees. This method results in a more accurate output class because it avoids the problem of overfitting by having variations (i.e. several decision trees). Moreover, adopting a Random Forest model depends on four steps: 1) use a sampled (bootstrapped) set, 2) create decision trees, 3) apply the model on a new set 4) evaluate. To conduct these steps, I will use both the caret package and the random forest package to practically implement the Random Forest model. 


```{r}
library(tidytext)
library(scales)
library(tidyverse)
require(quanteda)
require(quanteda.corpora)
require(quanteda.textstats)
library(car)
```

## Preparing The Data

Random Forests can be used either for classification or for regression. In this project, I used the classification method. I modified the State of The Union Speech data we used in class: I used the Sentiment score and readability in order to train the model to classify each document according to the political party   

```{r}

corp <- data_corpus_sotu

#creating the data frame 
final <- convert(corp, to = "data.frame")

#calculating text readability 
final <- textstat_readability(corp , "Flesch")


#calculating sentiment score 
token_sotu <- tokens(corp, split_hyphens = TRUE,
                remove_punct = TRUE,
                remove_numbers = TRUE
                ) %>%
  tokens_tolower(keep_acronyms = FALSE)
dfm_sotu <- dfm(token_sotu)

sent <- get_sentiments("bing")
sent_dict <- as.dictionary(sent)
dfm_sent <- dfm_lookup(dfm_sotu, dictionary = sent_dict)

dfm_sent_prop <- dfm_weight(dfm_sent, scheme = "prop") 

sentiment <- convert(dfm_sent_prop, "data.frame") %>%
  mutate(Sentiment = rescale(positive, to = c(-1,1)))

final <- cbind(final,sentiment)

#removing the redundant columns 
final <- select(final, -positive, -negative)
final <- select(final, -document)

final$party <- docvars(corp, 'party')

#recoding from a string to an integer in order to use it as a classifying variable 
final$party <- recode(final$party, " 'Independent' = 0 ; 'Democratic' = 1 
; 'Republican' = 2 
;  'Democratic-Republican' = 3 ; 
       'Federalist' = 4 ; 'Whig' = 5") 

head(final)
```
## Sampling and Splitting 
It is required to install caTools package to be able to use the sample function which allows us to take a sample out of the data and split it into a train set and a test set 
```{r}
#install.packages("caTools")      
#install.packages("randomForest") 

library(caTools)
library(randomForest)
```

```{r}
# Splitting data in train and test sets

sample <- sample(c(TRUE, FALSE), nrow(final), replace=TRUE, prob=c(0.7,0.3))
train  <- final[sample, ]
test   <- final[!sample, ]

```

Here, I specified the predictors (independent variables) and the classifying category (dependent variable)
```{r}
x_train <- train[-4]
y_train <- train$party
x_test <- test[-4]
y_test <- test$party
```

## Applying Random Forest on Train Data 

Here I applied the random forest model on the train set. The number of trees refers to the number of decision trees that the model follows in order to reach a majority vote, the default is 500. 

```{r}

set.seed(12)  # Setting seed
final_rf <- randomForest(
  formula = party ~ .,
  data    = final, 
                             ntree = 500) 
                         
                         #default (better to be many trees but too many can result in inaccuracy)

final_rf
```

In the model above, the out of bag error is estimated at 23.24% which means that the model has an accuracy rate of 77%. We can increase the number of decision trees to increase accuracy. 

A very minimal change occurred although we doubled the number of trees. 

```{r}
set.seed(12)  # Setting seed
final_rf2 <- randomForest(
  formula = party ~ .,
  data    = final, 
                             ntree = 1000) 
                         
                         #default (better to be many trees but too much can result in inaccuracy)

final_rf2


```

We can plot the random forests model using plot(). Additionally we can extract from the plot the number of trees that mirrors the minimum OOB error. In this plot, it is either falls at 180 0r 850 trees. 

```{r}
plot(final_rf2)

```

Instead of changing the number of trees arbitrary we can `tune` the model. Tuning is a method that allows us to manually shape our model. Here we want to know the mtry that mirrors the least OOB error. Mtry is the best split point that variables are split according to it. 

```{r}

mtry <- tuneRF(final[-1],final$party, ntreeTry=500,
               stepFactor=1.5,improve=0.01, trace=TRUE, plot = FALSE)
best.m <- mtry[mtry[, 2] == min(mtry[, 2]), 1]
print(mtry)
print(best.m)
```

From the code above, the best split point is 1 and it mirrors an 0.008% OOB error. We can now modify the model with the mtry that we extracted. The OOB error, estimated at 22.82%, is less than the one we had in our first model.
```{r}
set.seed(12)
final_rf3 <- randomForest(
  formula = party ~ .,
  data    = final, 
                             ntree = 1000, 
  mtry = best.m) 

final_rf3      
```



We have to install the caret package in order to extract a confusion matrix 
 
```{r}
#install.packages("caret")

library(caret)

```

Another way to test the accuracy of the model is through testing the predictions. This time the function gives back the accuracy rate itself and not the OOB error.
Accuracy equals 78%

```{r}
p1 <- predict(final_rf2, train)
confusionMatrix(p1, train$party)

```


## Testing and Validating

Here we will try our model on the test set. Random forest allows us to create a compound model so we could compare the results of the train set and the test set simultaneously. Our test OOB error is estimated at 40% which indicates that the accuracy rate of the model on the test set is 60% 
```{r}
set.seed(12)
compound_rf <- randomForest(
  formula = party~ .,
  data    = final,
  xtest   = x_test,
  ytest   = y_test,
ntree = 1000, 
mtry = 1)
compound_rf
```

It is obvious that there is a high OOB error in the test set and only 60% accuracy, which indicates that the model is not reliable. We can modify it by increasing the number of predictors, for example, distinctive words. This will give the model more information to work with.




